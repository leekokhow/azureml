{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial #2:  Deploy a classification model in Azure Container Instance (ACI)\n",
    "\n",
    "In the [previous tutorial](predict-employee-retention-part1-training.ipynb), you trained machine learning models and then registered a model in your workspace on the cloud.  \n",
    "\n",
    "Now, you're ready to deploy the model as a web service in [Azure Container Instances](https://docs.microsoft.com/azure/container-instances/) (ACI). The web service here is a Docker image that encapsulates the scoring logic and the model itself. \n",
    "\n",
    "In this part of the tutorial, you use Azure Machine Learning service to:\n",
    "\n",
    "* Set up your testing environment\n",
    "* Retrieve the model from your workspace\n",
    "* Test the model locally\n",
    "* Deploy the model to ACI\n",
    "* Test the deployed model\n",
    "\n",
    "ACI is a great solution for testing and understanding the workflow. For scalable production deployments, consider using Azure Kubernetes Service. For more information, see [how to deploy and where](https://docs.microsoft.com/azure/machine-learning/service/how-to-deploy-and-where).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to workspace\n",
    "\n",
    "Create a workspace object from the existing workspace. `Workspace.from_config()` reads the file **config.json** and loads the details into an object named `workspace`.\n",
    "\n",
    "If you see this message:\n",
    "\"Performing interactive authentication. Please follow the instructions on the terminal.\n",
    "To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code &lt;token\\&gt; to authenticate.\"\n",
    "    \n",
    "Click on the link and use the &lt;token\\&gt; given to authenticate. After authenticated, run this script again to get load the Workspace.&lt;/token\\&gt;&lt;/token\\&gt;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load workspace configuration from the config.json file in the current folder.\n",
    "from azureml.core import Workspace\n",
    "workspace = Workspace.from_config()\n",
    "print(workspace.name, workspace.location, workspace.resource_group, workspace.location, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Azure Machine Learning SDK for Python \n",
    "\n",
    "This step is to test you have installed Azure Machine Learning SDK for Python. Most of the coding will required the use of the Azure ML SDK. \n",
    "\n",
    "Display the Azure Machine Learning SDK version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "check version"
    ]
   },
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "\n",
    "# check core SDK version number (need Python 3.6 kernel if you run this in Microsoft Azure Notebooks)\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model locally\n",
    "\n",
    "Before deploying, make sure your model is working locally by:\n",
    "* Loading test data\n",
    "* Predicting test data\n",
    "* Examining the confusion matrix\n",
    "\n",
    "### Load test data\n",
    "\n",
    "Load the test data from Datastore. \n",
    "You can create your test data, but for simplicity this tutorial will only re-use the same dataset from Tutorial #1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "tabular_dataset = Dataset.get_by_name(workspace, name='predict-employee-retention-tabular').to_pandas_dataframe()\n",
    "\n",
    "# Process data...\n",
    "tabular_dataset = tabular_dataset.rename(columns={\"sales\": \"department\"})\n",
    "salary_map = {\"low\": 0, \"medium\": 1, \"high\": 2}\n",
    "tabular_dataset[\"salary\"] = tabular_dataset[\"salary\"].map(salary_map)\n",
    "tabular_dataset = pd.get_dummies(tabular_dataset, columns=[\"department\"], drop_first=True)\n",
    "display(tabular_dataset.describe())\n",
    "\n",
    "# Testing data\n",
    "X_test = tabular_dataset.loc[:, tabular_dataset.columns != \"left\"].values\n",
    "y_test = tabular_dataset.loc[:, tabular_dataset.columns == \"left\"].values.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the model\n",
    "\n",
    "You registered a model in your workspace in the previous tutorial. Now, load this workspace and download the model to your local directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "load workspace",
     "download model"
    ]
   },
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "from azureml.core.model import Model\n",
    "import os \n",
    "workspace = Workspace.from_config()\n",
    "model=Model(workspace, 'predict-employee-retention-model') # Default will get the latest version.\n",
    "\n",
    "model.download(target_dir=os.getcwd(), exist_ok=True)\n",
    "print(model)\n",
    "\n",
    "# Get the model file path.\n",
    "file_path = os.path.join(os.getcwd(), \"predict-employee-retention-model.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict test data\n",
    "\n",
    "Feed the test dataset to the model to get predictions.\n",
    "\n",
    "1. For local testing, use \"import joblib\".\n",
    "\n",
    "2. For the cloud compute, use \"from sklearn.externals import joblib\". To workaround the error \"ModuleNotFoundError: No module named 'sklearn.linear_model._logistic'\", need to use joblib from the older version of scikit-learn 0.20.3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib # Use this when retrieve model created on local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib # Use this when retrieve model created on cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = joblib.load(file_path)\n",
    "y_hat = clf.predict(X_test)\n",
    "\n",
    "# Quick test to determine the model is working! \n",
    "print(y_hat.shape) # you should see (14999,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy as web service\n",
    "\n",
    "Once you've tested the model and are satisfied with the results, deploy the model as a web service hosted in ACI. \n",
    "\n",
    "To build the correct environment for ACI, provide the following:\n",
    "* A scoring script to show how to use the model\n",
    "* An environment file to show what packages need to be installed\n",
    "* A configuration file to build the ACI\n",
    "* The model you trained before\n",
    "\n",
    "Note: the deployed web service can be found in your Workspace &gt; Deployments.\n",
    "\n",
    "### Create scoring script\n",
    "\n",
    "Create the scoring script, called score.py, used by the web service call to show how to use the model.\n",
    "\n",
    "You must include two required functions into the scoring script:\n",
    "* The `init()` function, which typically loads the model into a global object. This function is run only once when the Docker container is started. \n",
    "\n",
    "* The `run(input_data)` function uses the model to predict a value based on the input data. Inputs and outputs to the run typically use JSON for serialization and de-serialization, but other formats are supported.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile score.py\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from azureml.core.model import Model\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    # retrieve the path to the model file using the model name\n",
    "    model_path = Model.get_model_path('predict-employee-retention-model')\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "def run(raw_data):\n",
    "    data = np.array(json.loads(raw_data)['data'])\n",
    "    # make prediction\n",
    "    y_hat = model.predict(data)\n",
    "    # you can return any data type as long as it is JSON-serializable\n",
    "    return y_hat.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy in ACI\n",
    "Configure the image and deploy. The following code goes through these steps:\n",
    "\n",
    "1. Build an image using:\n",
    "   * The scoring file (`score.py`)\n",
    "   * The environment and resources required\n",
    "   * The model file\n",
    "1. Register that image under the workspace. \n",
    "1. Send the image to the ACI container.\n",
    "1. Start up a container in ACI using the image.\n",
    "1. Get the web service HTTP endpoint.\n",
    "\n",
    "The image can be found in your Azure ML Workspace &gt; Images.\n",
    "\n",
    "Note:\n",
    "If you see \"ERROR - Error, there is already a service with name sklearn-employee-retention-svc found in workspace <your workspace name>\", \n",
    "go to your **Azure ML Workspace &gt; Deployments**, where you can delete it if you need to recreate the service.\n",
    "\n",
    "\n",
    "This step may take a while to start after you run the cell, you will see the message \"Running\" appearing when it starts and will take few minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "configure image",
     "create image",
     "deploy web service",
     "aci"
    ]
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from azureml.core import Environment\n",
    "from azureml.core.model import InferenceConfig, Model\n",
    "from azureml.core.webservice import AciWebservice, Webservice\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "# Configure the environment to run the scoring script.\n",
    "env = Environment('my_env')\n",
    "cd = CondaDependencies.create(pip_packages=['azureml-sdk','azureml-defaults','scikit-learn==0.20.3'])\n",
    "env.python.conda_dependencies = cd\n",
    "\n",
    "# Combine scoring script & environment in Inference configuration\n",
    "inference_config = InferenceConfig(entry_script=\"score.py\", environment=env)\n",
    "\n",
    "# Set deployment configuration. While it depends on your model, the default of 1 core and 1 gigabyte of RAM \n",
    "# is usually sufficient for many models. If you feel you need more later, you would have to recreate the \n",
    "# image and redeploy the service.\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores=1, \n",
    "                                               memory_gb=1, \n",
    "                                               tags={\"data\": \"Employee retention\",  \"method\" : \"sklearn\"}, \n",
    "                                               description='Predict employee retention with sklearn')\n",
    "\n",
    "# Define the model, inference, & deployment configuration and web service name and location to deploy\n",
    "service = Model.deploy(\n",
    "    workspace = workspace,\n",
    "    name = \"sklearn-employee-retention-svc\",\n",
    "    models = [model],\n",
    "    inference_config = inference_config,\n",
    "    deployment_config = deployment_config)\n",
    "\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the scoring web service's HTTP endpoint, which accepts REST client calls. This endpoint can be shared with anyone who wants to test the web service or integrate it into an application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "get scoring uri"
    ]
   },
   "outputs": [],
   "source": [
    "service = Webservice(workspace=workspace, name='sklearn-employee-retention-svc')\n",
    "print(service.scoring_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test deployed service\n",
    "\n",
    "Test the deployed model with a random sample of 30 test data. For simplicity, the same\n",
    "training data is used.\n",
    "\n",
    "The following code goes through these steps:\n",
    "1. Send the data as a JSON array to the web service hosted in ACI. \n",
    "\n",
    "1. Use the SDK's `run` API to invoke the service. You can also make raw calls using any HTTP tool such as curl.\n",
    "\n",
    "1. Print the returned predictions. Red font is used to highlight the misclassified samples. \n",
    "\n",
    "1 = predict the employee will leave the organization\n",
    "\n",
    "0 = predict the employee will stay\n",
    "\n",
    "Run below code cell few times to see different predictions.\n",
    "\n",
    "Note: if you see the message \"Figure size 2000x100 with 30 Axes\" and nothing is displayed, re-run the code cell again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "score web service"
    ]
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# find 30 random samples from test set\n",
    "n = 30\n",
    "sample_indices = np.random.permutation(X_test.shape[0])[0:n]\n",
    "\n",
    "test_samples = json.dumps({\"data\": X_test[sample_indices].tolist()})\n",
    "test_samples = bytes(test_samples, encoding='utf8')\n",
    "\n",
    "# predict using the deployed model\n",
    "result = service.run(input_data=test_samples)\n",
    "\n",
    "# compare actual value vs. the predicted values:\n",
    "i = 0\n",
    "plt.figure(figsize = (20, 1))\n",
    "\n",
    "for s in sample_indices:\n",
    "    plt.subplot(1, n, i + 1)\n",
    "    plt.axhline('')\n",
    "    plt.axvline('')\n",
    "    \n",
    "    # use different color for misclassified sample\n",
    "    font_color = 'red' if y_test[s] != result[i] else 'black'\n",
    "        \n",
    "    plt.text(x=0, y=-5, s=result[i], fontsize=18, color=font_color)\n",
    "    plt.imshow(X_test[s].reshape(1, 17))\n",
    "    \n",
    "    i = i + 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also send raw HTTP request to test the web service. Run below code cell few times to see different predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": [
     "score web service"
    ]
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# send a random row from the test set to score\n",
    "random_index = np.random.randint(0, len(X_test)-1)\n",
    "input_data = \"{\\\"data\\\": [\" + str(list(X_test[random_index])) + \"]}\"\n",
    "\n",
    "headers = {'Content-Type':'application/json'}\n",
    "\n",
    "resp = requests.post(service.scoring_uri, input_data, headers=headers)\n",
    "\n",
    "print(\"POST to url\", service.scoring_uri)\n",
    "print(\"input data:\", input_data)\n",
    "print(\"label:\", y_test[random_index])\n",
    "print(\"prediction:\", resp.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up resources\n",
    "\n",
    "To keep the resource group and workspace for other tutorials and exploration, you can delete only the ACI deployment using this API call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "delete web service"
    ]
   },
   "outputs": [],
   "source": [
    "service.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also manually delete the deployed web service which can be found in your **Azure ML Workspace &gt; Deployments**.\n",
    "\n",
    "If you're not going to use what you've created here, delete the resources you just created so you don't incur any charges. "
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "roastala"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "msauthor": "sgilley"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
